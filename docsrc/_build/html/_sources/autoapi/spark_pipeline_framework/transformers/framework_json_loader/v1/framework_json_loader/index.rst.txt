:py:mod:`spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader`
==============================================================================================

.. py:module:: spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader.FrameworkJsonLoader




.. py:class:: FrameworkJsonLoader(view: str, filepath: Union[str, List[str], pathlib.Path], clean_column_names: bool = False, name: Optional[str] = None, progress_logger: Optional[spark_pipeline_framework.progress_logger.progress_logger.ProgressLogger] = None, parameters: Optional[Dict[str, Any]] = None, limit: int = -1, delimiter: str = ',', has_header: bool = True, infer_schema: bool = False, cache_table: bool = True, schema: Optional[pyspark.sql.types.StructType] = None, create_file_path: bool = False, use_schema_from_view: Optional[str] = None)

   Bases: :py:obj:`spark_pipeline_framework.transformers.framework_local_file_loader.v1.framework_local_file_loader.FrameworkLocalFileLoader`

   Abstract class for transformers that transform one dataset into another.

   .. versionadded:: 1.3.0

   .. py:method:: preprocess(self, df: pyspark.sql.dataframe.DataFrame, absolute_paths: List[str]) -> None

      In pre-processing we try to detect whether the file is a normal json or ndjson
      :param df: DataFrame
      :param absolute_paths: list of paths


   .. py:method:: setMultiLine(self, value: bool) -> FrameworkJsonLoader


   .. py:method:: getMultiLine(self) -> str


   .. py:method:: getReaderFormat(self) -> str


   .. py:method:: getReaderOptions(self) -> Dict[str, Any]



