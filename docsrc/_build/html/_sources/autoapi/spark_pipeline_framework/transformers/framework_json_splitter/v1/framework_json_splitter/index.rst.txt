:py:mod:`spark_pipeline_framework.transformers.framework_json_splitter.v1.framework_json_splitter`
==================================================================================================

.. py:module:: spark_pipeline_framework.transformers.framework_json_splitter.v1.framework_json_splitter


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   spark_pipeline_framework.transformers.framework_json_splitter.v1.framework_json_splitter.FrameworkJsonSplitter




.. py:class:: FrameworkJsonSplitter(file_path: Union[pathlib.Path, str], output_folder: Union[pathlib.Path, str], max_size_per_file_in_mb: float, name: Optional[str] = None, parameters: Optional[Dict[str, Any]] = None, progress_logger: Optional[spark_pipeline_framework.progress_logger.progress_logger.ProgressLogger] = None)

   Bases: :py:obj:`spark_pipeline_framework.transformers.framework_transformer.v1.framework_transformer.FrameworkTransformer`

   Abstract class for transformers that transform one dataset into another.

   .. versionadded:: 1.3.0

   .. py:method:: _transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame

      Transforms the input dataset.

      Parameters
      ----------
      dataset : :py:class:`pyspark.sql.DataFrame`
          input dataset.

      Returns
      -------
      :py:class:`pyspark.sql.DataFrame`
          transformed dataset


   .. py:method:: getFilePath(self) -> Union[pathlib.Path, str]


   .. py:method:: getOutputFolder(self) -> Union[pathlib.Path, str]


   .. py:method:: getMaxSizePerFileInMb(self) -> float



