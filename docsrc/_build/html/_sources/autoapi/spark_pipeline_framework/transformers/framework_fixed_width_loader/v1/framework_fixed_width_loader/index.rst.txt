:py:mod:`spark_pipeline_framework.transformers.framework_fixed_width_loader.v1.framework_fixed_width_loader`
============================================================================================================

.. py:module:: spark_pipeline_framework.transformers.framework_fixed_width_loader.v1.framework_fixed_width_loader


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   spark_pipeline_framework.transformers.framework_fixed_width_loader.v1.framework_fixed_width_loader.ColumnSpec
   spark_pipeline_framework.transformers.framework_fixed_width_loader.v1.framework_fixed_width_loader.FrameworkFixedWidthLoader




.. py:class:: ColumnSpec

   Bases: :py:obj:`NamedTuple`

   The definition of a column for fixed width file formats
       column_name: the name of the column

       start_pos: the starting position of the data for this column in the file

       length: the length of the data for this column

       data_type: the data type for the data in the column, e.g. StringType(), IntegerType()

   example:
     ColumnSpec(column_name="id", start_pos=1, length=3, data_type=StringType())

   .. py:attribute:: column_name
      :annotation: :str

      

   .. py:attribute:: start_pos
      :annotation: :int

      

   .. py:attribute:: length
      :annotation: :int

      

   .. py:attribute:: data_type
      :annotation: :pyspark.sql.types.DataType

      


.. py:class:: FrameworkFixedWidthLoader(view: str, filepath: Union[str, List[str], pathlib.Path], columns: List[ColumnSpec], has_header: bool = True, name: Optional[str] = None, parameters: Optional[Dict[str, Any]] = None, progress_logger: Optional[spark_pipeline_framework.progress_logger.progress_logger.ProgressLogger] = None)

   Bases: :py:obj:`spark_pipeline_framework.transformers.framework_transformer.v1.framework_transformer.FrameworkTransformer`

   Load fixed width files into a dataframe by specifying the path to the file and the schema

   .. py:method:: _transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame

      Transforms the input dataset.

      Parameters
      ----------
      dataset : :py:class:`pyspark.sql.DataFrame`
          input dataset.

      Returns
      -------
      :py:class:`pyspark.sql.DataFrame`
          transformed dataset


   .. py:method:: getView(self) -> str


   .. py:method:: getFilepath(self) -> Union[str, List[str], pathlib.Path]


   .. py:method:: getColumns(self) -> List[ColumnSpec]


   .. py:method:: getHasHeader(self) -> bool



