:mod:`spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader`
===========================================================================================

.. py:module:: spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader.FrameworkJsonLoader



.. class:: FrameworkJsonLoader(view: str, filepath: Union[(str, List[str], Path)], clean_column_names: bool = False, name: Optional[str] = None, progress_logger: Optional[ProgressLogger] = None, parameters: Optional[Dict[str, Any]] = None, **kwargs: Dict[(Any, Any)])


   Bases: :class:`spark_pipeline_framework.transformers.framework_local_file_loader.v1.framework_local_file_loader.FrameworkLocalFileLoader`

   Abstract class for transformers that transform one dataset into another.

   .. versionadded:: 1.3.0

   .. method:: preprocess(self, df: pyspark.sql.dataframe.DataFrame, absolute_paths: List[str]) -> None

      In pre-processing we try to detect whether the file is a normal json or ndjson
      :param df: DataFrame
      :param absolute_paths: list of paths


   .. method:: setMultiLine(self, value: bool) -> spark_pipeline_framework.transformers.framework_json_loader.v1.framework_json_loader.FrameworkJsonLoader


   .. method:: getMultiLine(self) -> str


   .. method:: getReaderFormat(self) -> str


   .. method:: getReaderOptions(self) -> Dict[(str, Any)]



