:mod:`spark_pipeline_framework.transformers.framework_json_splitter.v1.framework_json_splitter`
===============================================================================================

.. py:module:: spark_pipeline_framework.transformers.framework_json_splitter.v1.framework_json_splitter


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   spark_pipeline_framework.transformers.framework_json_splitter.v1.framework_json_splitter.FrameworkJsonSplitter



.. class:: FrameworkJsonSplitter(file_path: Union[(Path, str)], output_folder: Union[(Path, str)], max_size_per_file_in_mb: float, name: Optional[str] = None, parameters: Optional[Dict[str, Any]] = None, progress_logger: Optional[ProgressLogger] = None)


   Bases: :class:`spark_pipeline_framework.transformers.framework_transformer.v1.framework_transformer.FrameworkTransformer`

   Abstract class for transformers that transform one dataset into another.

   .. versionadded:: 1.3.0

   .. method:: setParams(self, file_path: Union[(Path, str)], output_folder: Union[(Path, str)], max_size_per_file_in_mb: float, name: Optional[str] = None, parameters: Optional[Dict[str, Any]] = None, progress_logger: Optional[ProgressLogger] = None) -> Any


   .. method:: _transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame

      Transforms the input dataset.

      :param dataset: input dataset, which is an instance of :py:class:`pyspark.sql.DataFrame`
      :returns: transformed dataset


   .. method:: getFilePath(self) -> Union[(Path, str)]


   .. method:: getOutputFolder(self) -> Union[(Path, str)]


   .. method:: getMaxSizePerFileInMb(self) -> float



