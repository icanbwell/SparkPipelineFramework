[[source]]
url = "https://pypi.python.org/simple"
verify_ssl = true
name = "pypi"

[packages]
logger = ">=1.4"
protobuf=">=3"
pyspark = ">=3.1.1"
sparkautomapper = ">=1.1.1"
pymysql=">=1.0.2"
furl = ">=2.1.3"
requests = ">=2.27.1"
boto3 = ">=1.26.76"
chardet=">=4.0.0"
slack_sdk = ">=3.20.0"
smart_open = { extras = ['s3'], version = ">=6.3.0" }
mlflow-skinny = ">=1.26.0"
SQLAlchemy = ">=1.4.37"
alembic = ">=1.8.0"
sqlparse = ">=0.4.2"
bounded-pool-executor = ">=0.0.3"
fastjsonschema= "*"
"helix.fhir.client.sdk" = ">=1.0.33"
opensearch-py= "*"
pyathena = "*"
spark-nlp = ">=4.2.2"
tensorflow = "*"
delta-spark=">=2.1.0"
pymongo="==4.2.0"

[dev-packages]
setuptools=">=67.4.0"
wheel=">=0.38.4"
twine=">=3.8.0"
pre-commit=">=2.20.0"
autoflake=">=1.7.7"
mypy = ">=1.0.1"
pytest = ">=7.1.3"
black = ">=22.12.0"
pygments=">=2.8.1" # not directly required, pinned by Snyk to avoid a vulnerability
Sphinx="==4.1.2"
sphinx-autoapi="==1.8.4"
sphinx-rtd-theme="==0.5.2"
myst-parser="==0.15.1"
recommonmark="==0.7.1"
py4j = "==0.10.9.5" # https://spark.apache.org/docs/latest/api/python/getting_started/install.html#dependencies
pyspark="==3.3.0"  # should match the version of spark we use for testing
pipenv-setup = ">=3.2.0"
Deprecated = "==1.2.12"
sparkdataframecomparer = "==1.0.8"
pytest-asyncio = ">=0.20.3"
vistir="==0.6.1" # https://github.com/Madoshakalaka/pipenv-setup/issues/138
helix-mockserver-client=">=1.0.3"
sparkfhirschemas = "==1.0.14"
types-boto3 = ">=1.0.2"
moto = ">=4.1.3"
types-requests=">=0.1.11"
types-PyMySQL=">=0.1.5"


[requires]
python_version = "3.7"

[pipenv]
allow_prereleases = true
