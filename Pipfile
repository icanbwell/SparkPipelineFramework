[[source]]
url = "https://pypi.python.org/simple"
verify_ssl = true
name = "pypi"

[packages]
logger = ">=1.4"
protobuf=">=3.20.*"
pyspark = ">=3.1.1"
sparkautomapper = ">=1.0.19"
pymysql="==1.0.2"
furl = ">=2.1.3"
requests = ">=2.27.1"
boto3 = ">=1.21.32"
types-requests=">=0.1.11"
types-PyMySQL=">=0.1.5"
chardet=">=4.0.0"
slack_sdk = ">=3.19.3"
smart_open = { extras = ['s3'], version = ">=5.2.1" }
mlflow-skinny = ">=1.26.0"
SQLAlchemy = ">=1.4.37"
alembic = ">=1.8.0"
sqlparse = ">=0.4.2"
bounded-pool-executor = ">=0.0.3"
fastjsonschema= "*"
"helix.fhir.client.sdk" = ">=1.0.29"
opensearch-py= "*"
pyathena = "*"
delta-spark=">=2.1.0"

[dev-packages]
setuptools=">=61.3.1"
wheel=">=0.37.1"
twine=">=3.8.0"
pre-commit=">=2.20.0"
autoflake=">=1.7.7"
mypy = "==0.990"
pytest = "==7.2.0"
black = ">=22.10.0"
pygments=">=2.8.1" # not directly required, pinned by Snyk to avoid a vulnerability
Sphinx="==4.1.2"
sphinx-autoapi="==1.8.4"
sphinx-rtd-theme="==0.5.2"
myst-parser="==0.15.1"
recommonmark="==0.7.1"
py4j = "==0.10.9.5" # https://spark.apache.org/docs/latest/api/python/getting_started/install.html#dependencies
pyspark="==3.3.0"  # should match the version of spark we use for testing
pipenv-setup = ">=3.2.0"
Deprecated = "==1.2.12"
sparkdataframecomparer = "==1.0.7"
pytest-asyncio = ">=0.19.0"
vistir="==0.6.1" # https://github.com/Madoshakalaka/pipenv-setup/issues/138
helix-mockserver-client=">=1.0.0"
"sparkfhirschemas" = "==1.0.14"
types-boto3 = ">=1.0.2"
moto = ">=4.0.9"

[requires]
python_version = "3.7"

[pipenv]
allow_prereleases = false
