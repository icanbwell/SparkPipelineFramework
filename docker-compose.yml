version: '3.5'
services:
  dev:
    user: root
    build:
      dockerfile: spark.Dockerfile
      context: .
    environment:
      - AWS_ACCESS_KEY_ID
      - AWS_DEFAULT_REGION
      - AWS_SECRET_ACCESS_KEY
      - AWS_SECURITY_TOKEN
      - AWS_SESSION_TOKEN
    volumes:
      - ./:/SparkpipelineFramework/
    container_name: spf_dev
    working_dir: /SparkpipelineFramework

  spark:
    user: root
    image: sparkpipelineframework_dev:latest
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
      - '7077:7077'
      - '4040:4040'
    restart: always
    healthcheck:
        test: ["CMD-SHELL", "/opt/bitnami/spark/bin/spark-submit --master spark://spark:7077 /opt/bitnami/spark/examples/src/main/python/pi.py 10"]
        timeout: 300s
        retries: 5
        start_period: 60s 

  warehouse:
    image: mysql:5.7
    volumes:
      - mysql_data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: root_password
      MYSQL_DATABASE: fhir_rpt
    ports:
      - '33061:3306'
    command: --sql-mode="STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION"
    healthcheck:
      test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]

  mlflow:
    image: imranq2/mlflow_server:0.1.6
    ports:
      - '5050:5000'
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri mysql+pymysql://root:root_password@warehouse:3306/fhir_rpt --default-artifact-root ./mlruns 
      
volumes:
  mysql_data:
    labels:
      - "mlflow"
